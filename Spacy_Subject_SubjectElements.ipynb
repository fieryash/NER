{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xx8mdA6g0SyD"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "N5yRHmSWwCuk",
    "outputId": "da64884d-5e16-4aab-8f4a-ae3ae0003500"
   },
   "outputs": [],
   "source": [
    "#Spacy uses Jsonlines for training\n",
    "!pip install jsonlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "P8UpTUPIv0iz",
    "outputId": "da9fb4fb-077b-45be-b736-bdceeef0c05b"
   },
   "outputs": [],
   "source": [
    "import jsonlines\n",
    "import string \n",
    "import pandas as pd\n",
    "import json\n",
    "import glob\n",
    "import random\n",
    "import re\n",
    "\n",
    "#Spacy imports\n",
    "import spacy\n",
    "from spacy.gold import GoldParse\n",
    "from spacy.scorer import Scorer\n",
    "from spacy import displacy\n",
    "from collections import Counter\n",
    "from spacy.util import minibatch, compounding\n",
    "from spacy.util import decaying\n",
    "\n",
    "import warnings\n",
    "import pickle\n",
    "import plac\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "spacy.prefer_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0-s1Ahwlv8TD"
   },
   "outputs": [],
   "source": [
    "#reading the json1 file for the Dataset\n",
    "lst = []\n",
    "for file in glob.glob(\"*.json1\"):\n",
    "    with jsonlines.open(file) as reader:\n",
    "        for obj in reader:\n",
    "            lst.append(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "7UjYhL2Jwuzk",
    "outputId": "6e69650f-4cef-4341-91d2-46b7a67b7a1a"
   },
   "outputs": [],
   "source": [
    "#creating the dataset (which will be cleaned in further steps)\n",
    "Dataset = []\n",
    "for data in lst:\n",
    "    ents = [tuple(entity) for entity in data['labels']]\n",
    "    Dataset.append((data['text'].lower().strip(),{'entities':ents}))\n",
    "random.shuffle(Dataset)\n",
    "test_dataset = Dataset[641:741]\n",
    "Dataset = Dataset[0:641]\n",
    "print(len(Dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ojr0faHnwyhv"
   },
   "outputs": [],
   "source": [
    "#creating a dictionary of the annotations\n",
    "def create_dict(x):\n",
    "    dictionary = {}\n",
    "    text = x[0]\n",
    "    annot = x[1]\n",
    "    index = annot['entities']\n",
    "    for start,end,tag in index:\n",
    "        word = text[start:end].lower().strip()\n",
    "        dictionary[word]=tag\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "odLyfUQawzsc",
    "outputId": "682661b4-98a2-4d0f-8b1b-b58f8e96f9b0"
   },
   "outputs": [],
   "source": [
    "dictionary = {}\n",
    "for val in Dataset:\n",
    "    tmp_dict = create_dict(val)\n",
    "#     print(tmp_dict)\n",
    "#     break\n",
    "    dictionary.update(tmp_dict)\n",
    "    \n",
    "\n",
    "dictionary = {k.strip().lower(): v for (k, v) in dictionary.items()}\n",
    "len(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "elHfoiEIw0tI"
   },
   "outputs": [],
   "source": [
    "dict_keys = dictionary.keys()\n",
    "# dict_keys\n",
    "# dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aPWQ9z-s5pqW"
   },
   "outputs": [],
   "source": [
    "# Dataset[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7cUq5IqhEEqH"
   },
   "outputs": [],
   "source": [
    "#Checking if overlapping annotations exist. For example \"Judgement and udgement(wrongly annotated)\" or \"Supreme Court and\"\n",
    "def is_overlap(a, b):\n",
    "    a, b = sorted([a, b])\n",
    "    if a[0] <= b[0] and a[1] >= b[1]:\n",
    "        return True\n",
    "    elif a[1] > b[0]:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qs0c9BEJD2q6"
   },
   "outputs": [],
   "source": [
    "# assert is_overlap((1,9), (3,4)) == True\n",
    "# assert is_overlap((3,4), (1,9)) == True\n",
    "# assert is_overlap((1, 5), (3, 7)) == True\n",
    "# assert is_overlap((4, 9), (1, 6)) == True\n",
    "# assert is_overlap((1,6), (7,9)) == False\n",
    "# assert is_overlap((1,4),(4,6)) == False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JH-xC4HQEw_N"
   },
   "outputs": [],
   "source": [
    "# dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q8pZT_MmEpHz"
   },
   "outputs": [],
   "source": [
    "# [k for k in dictionary if len(k) == 44]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kHbSlbJvEfbG"
   },
   "outputs": [],
   "source": [
    "# from collections import Counter\n",
    "# Counter(map(len, dictionary)).most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ITJo3y_2HcjD"
   },
   "outputs": [],
   "source": [
    "# sorted(dictionary.items(), key=lambda x: len(x[0]), reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xT8JOzgtM7n9"
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DUIYydQ5M7n_"
   },
   "outputs": [],
   "source": [
    "#Script to clean out the annotations\n",
    "dictionary2 = {re.compile(re.escape(k)): v for k,v in sorted(dictionary.items(), key=lambda x: len(x[0]), reverse=True) if len(k) >= 4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CIyLweHsw3Dn"
   },
   "outputs": [],
   "source": [
    "#Script to re-annotate the dataset\n",
    "from __future__ import unicode_literals, print_function\n",
    "def entities_finder(document):  \n",
    "    entities = []\n",
    "    my_str=document\n",
    "    some_list= set()\n",
    "    for key, final_tag in dictionary2.items():\n",
    "        start = 0\n",
    "        for match in key.finditer(my_str):\n",
    "            out_interval = match.span()\n",
    "            if out_interval in some_list:\n",
    "                continue\n",
    "            if not any(is_overlap(out_interval, interval) for interval in some_list):\n",
    "                entities.append((out_interval[0], out_interval[1], final_tag))\n",
    "                some_list.add(out_interval)\n",
    "\n",
    "    return entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qkioIN6fxA9y"
   },
   "outputs": [],
   "source": [
    "#To store in the format specified for Spacy\n",
    "def formatting_func(text):\n",
    "    val=(text,{'entities':entities_finder(text)})\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 151
    },
    "colab_type": "code",
    "id": "aW3QXfOaxDDo",
    "outputId": "4f643a3b-4f51-4de5-8fe0-124fac49a0e0"
   },
   "outputs": [],
   "source": [
    "cleaned_dataset=[]\n",
    "for i in tqdm(sorted(Dataset, key=lambda x: len(x[0]))):\n",
    "    cleaned_dataset.append(formatting_func(i[0]))\n",
    "cleaned_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gJl3Wi-hM7oI"
   },
   "outputs": [],
   "source": [
    "# len(sorted(Dataset, key=lambda x: len(x[0]),reverse=True)[3][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o-DCWJEhM7oK"
   },
   "outputs": [],
   "source": [
    "# len(sorted(Dataset, key=lambda x: len(x[0]),reverse=True)[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7PhYLReFM7oM"
   },
   "outputs": [],
   "source": [
    "# len(cleaned_dataset[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b9FxGVzhxV9u"
   },
   "outputs": [],
   "source": [
    "random.shuffle(cleaned_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "7BQe3ONzxJN5",
    "outputId": "71f58cce-c990-4ea5-b47b-85a9323a33e5"
   },
   "outputs": [],
   "source": [
    "train_set = cleaned_dataset[:500]\n",
    "len(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "U9a09xtjxSyc",
    "outputId": "e81c4e9e-b5a5-4695-cc0e-35512e6fee96"
   },
   "outputs": [],
   "source": [
    "test_set = cleaned_dataset[500:]\n",
    "len(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kYsmGKFS660z"
   },
   "outputs": [],
   "source": [
    "def evaluate(ner_model, examples):\n",
    "    scorer = Scorer()\n",
    "    for input_, annot in examples:\n",
    "        doc_gold_text = ner_model.make_doc(input_)\n",
    "        gold = GoldParse(doc_gold_text, entities=annot['entities'])\n",
    "        pred_value = ner_model(input_)\n",
    "        scorer.score(pred_value, gold)\n",
    "    return scorer.scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 574
    },
    "colab_type": "code",
    "id": "L3rQ26a7xawN",
    "outputId": "8daa5dd1-4122-4f82-bbe5-4030aea557b1"
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf8\n",
    "\n",
    "# Training additional entity types using spaCy\n",
    "\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "LABEL = ['Authority', 'Action', 'Area', 'Party', 'Subject', 'SubjectElements'] #currently used annotations\n",
    "def main(model=None, new_model_name='new_model', output_dir=\"/content/\", n_iter=15):\n",
    "    \"\"\"Setting up the pipeline and entity recognizer, and training the new entity.\"\"\"\n",
    "    max_batch_size = 16\n",
    "    if len(train_set) < 500:\n",
    "        max_batch_size /= 2\n",
    "    nlp = spacy.blank('en')  # create blank Language class\n",
    "    print(\"Created blank 'en' model\")\n",
    "    if 'ner' not in nlp.pipe_names:\n",
    "        ner = nlp.create_pipe('ner')\n",
    "        nlp.add_pipe(ner)\n",
    "    else:\n",
    "        ner = nlp.get_pipe('ner')\n",
    "\n",
    "    for i in LABEL:\n",
    "        ner.add_label(i)   # Add new entity labels to entity recognizer\n",
    "\n",
    "    if model is None:\n",
    "        optimizer = nlp.begin_training()\n",
    "    else:\n",
    "        optimizer = nlp.entity.create_optimizer()\n",
    "\n",
    "    # Get names of other pipes to disable them during training to train only NER\n",
    "    other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']\n",
    "    with nlp.disable_pipes(*other_pipes):  # only train NER\n",
    "        for itn in range(n_iter):\n",
    "            random.shuffle(train_set)\n",
    "            losses = {}\n",
    "            batches = minibatch(train_set, size=compounding(1, max_batch_size, 1.001))\n",
    "            for batch in batches:\n",
    "                texts, annotations = zip(*batch)\n",
    "                nlp.update(texts, annotations, sgd=optimizer, drop=0.5,\n",
    "                           losses=losses)\n",
    "            scores = evaluate(nlp, train_set)\n",
    "            print(\"Scores \",scores)\n",
    "            print('Losses', losses)\n",
    "                # Save model \n",
    "    if output_dir is not None:\n",
    "        output_dir = Path(output_dir)\n",
    "        if not output_dir.exists():\n",
    "            output_dir.mkdir()\n",
    "        nlp.meta['name'] = new_model_name  # rename model\n",
    "        nlp.to_disk(output_dir)\n",
    "        print(\"Saved model to\", output_dir)\n",
    "            \n",
    "prdnlp = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "p_g6G8RExd5S",
    "outputId": "1c5d9dac-e8fa-4ad9-cbda-88f004126b30"
   },
   "outputs": [],
   "source": [
    "# to render the generated annotations\n",
    "nlp2 = spacy.load(\"/content\")\n",
    "doc = nlp2(test_dataset[5][0])\n",
    "displacy.render(nlp2(str(doc)), jupyter=True, style='ent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "nkAMQQrvxm46",
    "outputId": "1c914d93-6f04-4acf-ec67-7c0d0f186221"
   },
   "outputs": [],
   "source": [
    "#Evaluate the model on the test_set created after auto-annotations\n",
    "examples = test_set\n",
    "results = evaluate(nlp2, examples)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P9Ic4OsQ5an3"
   },
   "outputs": [],
   "source": [
    "# This checks for mis-alignments in the annotations shown by ('-'). Spacy ignores these as a Userwarning\n",
    "# But too many mis-alignments will lead to a crunch in your train set\n",
    "\n",
    "# from spacy.gold import biluo_tags_from_offsets\n",
    "# for text, annot in train_set:\n",
    "#     doc = nlp2.make_doc(text)\n",
    "#     print(biluo_tags_from_offsets(doc, annot[\"entities\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "SpacyFinal_.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
